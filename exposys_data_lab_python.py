# -*- coding: utf-8 -*-
"""exposys_data_lab_internship.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17i4OKnE6ZbsEN_zIjNB0ky3KVGPo0Lx6
"""

# importing different libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

#loading Data
data = pd.read_csv('/content/50_Startups.csv')

"""**Data Overview**"""

print("Dataset Overview:")
# seeing 1st 5 rows of data
print(data.head())

print("\nDataset Information:")
print(data.info())

print("\nMissing Values in Each Column:")
print(data.isnull().sum())

print("\nStatistical Summary:")
print(data.describe())

plt.figure(figsize=(8, 6))
sns.scatterplot(x=data['R&D Spend'], y=data['Profit'], hue=data['Marketing Spend'], palette='coolwarm')
plt.title('R&D Spend vs Profit with Marketing Spend Hue')
plt.show()

plt.figure(figsize=(8, 6))
sns.scatterplot(x=data['Administration'], y=data['Profit'], hue=data['R&D Spend'], palette='viridis')
plt.title('Administration Spend vs Profit with R&D Spend Hue')
plt.xlabel('Administration Spend')
plt.ylabel('Profit')
plt.show()

plt.figure(figsize=(8, 6))
sns.barplot(x=data['Marketing Spend'], y=data['Profit'], palette='plasma')
plt.title('Marketing Spend vs Profit')
plt.xlabel('Marketing Spend')
plt.ylabel('Profit')
plt.show()

sns.pairplot(data, palette='coolwarm')
plt.suptitle("Pairplot of Features", y=1.02)
plt.show()

plt.figure(figsize=(10, 6))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

if 'State' in data.columns:
    data = pd.get_dummies(data, columns=['State'], drop_first=True)

X = data.drop('Profit', axis=1)
y = data['Profit']

# splitting data into test and train
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

models = {
    "Linear Regression": LinearRegression(),
    "Ridge Regression": Ridge(),
    "Lasso Regression": Lasso(),
    "Random Forest Regressor": RandomForestRegressor(random_state=42)
}

results = []

results = []

for name, model in models.items():
    model.fit(X_train, y_train)
    # Predict on the test set
    y_pred = model.predict(X_test)
    # Calculating metrics
    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)
    accuracy = max(0, r2) * 100
    # Appending results
    results.append({
        "Model": name,
        "MAE": mae,
        "MSE": mse,
        "RMSE": rmse,
        "R² Score": r2,
        "Accuracy (%)": accuracy
    })

results_df = pd.DataFrame(results)
print("\nModel Performance Comparison:")

print(results_df)

best_model = results_df.loc[results_df['R² Score'].idxmax()]
print(f"\nBest Model: {best_model['Model']}")
print(f"Best Model R² Score: {best_model['R² Score']}")

best_model = results_df.loc[results_df['Accuracy (%)'].idxmax()]
print(f"\nBest Model: {best_model['Model']}")
print(f"Best Model Accuracy: {best_model['Accuracy (%)']:.2f}%")

results_df.to_csv('model_performance_comparison.csv', index=False)

if best_model['Model'] == "Random Forest Regressor":
    import joblib
    best_model_instance = RandomForestRegressor(random_state=42)
    best_model_instance.fit(X_train, y_train)
    joblib.dump(best_model_instance, 'best_model.pkl')

print(f"Model type: {type(best_model)}")

if best_model['Model'] == "Random Forest Regressor":
    # Train the model
    best_model_instance = RandomForestRegressor(random_state=42)
    best_model_instance.fit(X_train, y_train)

    # Save the trained model
    joblib.dump(best_model_instance, 'best_model.pkl')
    print("Model saved successfully.")
else:
    print("Model type doesn't match 'Random Forest Regressor'.")

best_model_instance = joblib.load('best_model.pkl')
print(f"Model type: {type(best_model_instance)}")
trained_feature_columns = ['R&D Spend', 'Administration', 'Marketing Spend']

# Now use best_model_instance for predictions
def user_input_predict_colab(model, data, feature_columns):
    def suggest_input_ranges(data):
        print("\nSuggested input ranges based on the dataset:")
        for column in ['R&D Spend', 'Administration', 'Marketing Spend']:
            if column in data.columns:
                min_val = data[column].min()
                max_val = data[column].max()
                mean_val = data[column].mean()
                print(f"- {column}: Min: {min_val:.2f}, Max: {max_val:.2f}, Avg: {mean_val:.2f}")

    suggest_input_ranges(data)

    try:
        rd_spend = float(input("Enter R&D Spend: "))
        administration = float(input("Enter Administration Spend: "))
        marketing_spend = float(input("Enter Marketing Spend: "))
    except ValueError:
        print("Invalid input! Please enter numeric values for spends.")
        return

    new_data_dict = {
        'R&D Spend': rd_spend,
        'Administration': administration,
        'Marketing Spend': marketing_spend,
    }

    new_data = pd.DataFrame([new_data_dict])[feature_columns]

    prediction = model.predict(new_data)
    print(f"\nPredicted Profit: {prediction[0]:.2f}")

user_input_predict_colab(best_model_instance, data, trained_feature_columns)

data.tail()

